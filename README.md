# ONET MCP Server

Un serveur **MCP** l√©ger et performant con√ßu pour interroger l'API **O*NET Web Services**. Il fournit des fiches m√©tiers structur√©es et enrichies pour les agents d'IA. 
Il expose ses outils via le transport **SSE (Server-Sent Events)**.
Le serveur expose deux tools MCP:
- recherche de metier par mot-cle
- rapport complet d'un metier a partir d'un code SOC

## Fonctionnalites ‚ú®
* **Protocole MCP complet** : Support du transport SSE pour une communication fluide.
* **Recherche intelligente** : Recherche de m√©tiers par mot-cl√© (retourne les codes SOC).
* **Enrichissement de donn√©es** : G√©n√©ration de rapports complets (T√¢ches, Skills, Knowledge, Tech, Education, etc.).
* **Performance** : Agr√©gation asynchrone des appels API O*NET (via `httpx` et `asyncio.gather`) pour des r√©ponses rapides.

## Prerequis üõ†Ô∏è
- Python 3.10+
- Une cle API O*NET (Web Services) valide

## Installation

```bash
# Cr√©er un environnement virtuel
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

## Configuration
Creer un fichier `.env` a la racine du projet:
```
ONET_API_KEY=VOTRE_CLE_API
PORT=8000
```

## Lancer le serveur

```bash
python main.py
```
Le serveur d√©marrera sur `http://0.0.0.0:8000/sse`

### Utilisation (Agent AI)

Vous pouvez connecter un agent Python (dans un autre projet) √† ce serveur pour lui donner acc√®s aux donn√©es O*NET.

**Installation du client dans votre autre projet :**

```bash
pip install mcp

```

**Exemple de code pour l'Agent :**

```python
import asyncio
from mcp.client.sse import sse_client
from mcp.client.session import ClientSession

# URL de votre serveur d√©ploy√© (ou localhost)
SERVER_URL = "http://localhost:8000/sse" 
# En production ex: "https://onet.votre-domaine.com/sse"

async def run_agent_tool():
    # Connexion au flux SSE
    async with sse_client(SERVER_URL) as (read, write):
        async with ClientSession(read, write) as session:
            # 1. Initialisation (Handshake)
            await session.initialize()
            
            # 2. Lister les outils disponibles
            tools = await session.list_tools()
            print(f"Outils connect√©s : {[t.name for t in tools.tools]}")

            # 3. Ex√©cuter un outil (Ex: Rechercher un m√©tier)
            print("--- Recherche 'Python Developer' ---")
            search_result = await session.call_tool(
                "search_occupation",
                arguments={"keyword": "Python Developer"}
            )
            print(search_result.content[0].text)

            # 4. Ex√©cuter un outil (Ex: D√©tails d'un code SOC)
            print("\n--- D√©tails pour SOC 15-1252.00 ---")
            details_result = await session.call_tool(
                "get_occupation_details",
                arguments={"soc_code": "15-1252.00"}
            )
            print(details_result.content[0].text)

if __name__ == "__main__":
    asyncio.run(run_agent_tool())

```


## üß∞ Tools Disponibles

1) `search_occupation`
Recherche des m√©tiers correspondants √† un mot-cl√©.
- **Input :** `keyword` (str)
- **Output :** liste Markdown des metiers et codes SOC correspondants.

2) `get_occupation_details`
R√©cup√®re la fiche compl√®te d'un m√©tier via son code SOC.
- Entree: `soc_code` (str)
- Sortie: Rapport metier complet au format Markdown

## üìÇ Structure du projet
* `main.py`: point d'entree du serveur (Configuration Starlette/SSE & Routes MCP)
* `app/`
* `client.py` : Client HTTP asynchrone pour l'API O*NET.
* `logic.py` : Logique m√©tier et orchestration des appels.
* `formatters.py` : Transformation des donn√©es JSON brutes en Markdown lisible pour les LLMs.
* `requirements.txt`: dependances
* `Dockerfile` : Configuration pour la conteneurisation.

## Notes
* Les appels API vers O*NET sont parall√©lis√©s pour garantir que la g√©n√©ration du rapport complet (qui n√©cessite ~10 appels API distincts) reste rapide.
* Le formatage Markdown est optimis√© pour √™tre facilement ing√©r√© et compris par les LLMs.